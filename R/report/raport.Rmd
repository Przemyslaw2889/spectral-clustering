---
title: "Spectral clustering - raport"
author: "Przemysław Kaleta"
date: "January 25, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
```

## Użyteczne funkcje

Poniżej kod do wczytywania danych i rysowania wykresów. Kod, którego użyłem do zapisania wyników można znaleźć w pliku `raport.R`.

```{r, message=FALSE}
library(mclust)
library(dendextend)
library(genie)
library(dbscan)
library(stringi)

source("spectral.R")

read_data <- function(benchmark, dataset){
  matrix_file_name <- paste(dataset, ".data.gz", sep="")
  labels_file_name <- paste(dataset, ".labels0.gz", sep="")
  matrix_path <- file.path("..", "benchmarks", benchmark, matrix_file_name)
  labels_path <- file.path("..", "benchmarks", benchmark, labels_file_name)
  X <- as.matrix(read.table(matrix_path))
  Y <- as.matrix(read.table(labels_path))
  return(list(X=X, Y=Y))
}
  
plot_data <- function(X, Y, title=""){
  plot(X[, 1], X[, 2], col=unlist(Y), pch=20)
  title(title)
}
```

## Analiza wyników
```{r, cache=TRUE}
result <- read.csv("results.csv")
```

### Ktory algorytm jest najlepszy?
```{r, cache=TRUE}
result %>% select(algorithm, FM, AR) %>% 
  group_by(algorithm) %>% summarise(mean_FM = mean(FM), mean_AR = mean(AR)) %>%
  arrange(desc(mean_FM))
```
Cieszymy się patrząc na te wyniki, bo widzimy że spectral clustering nie jest na końcu. Nie odstaje tak bardzo od metod funkcji `hclust`. Jedynie `genie` znacząco wyprzedza je wszystkie, zarówno dla miary FM jak i (zwłaszcza) AR. 

### Czy genie rzeczywiście jest najlepszy?


Nie ufamy za bardzo tym wynikom. Któryś z algorytmów musiał mieć największy wynik FM, ale być może było to całkiem przypadkowe. Dlatego sprawdźmy czy możemy mówić o statystycznej istotności tego wyniku. 

```{r, warning=FALSE}
genie_result <- unlist(result %>% filter(algorithm == "genie") %>% select(FM))
hclust_result <- unlist(result %>% filter(algorithm == "hclust_average") %>% select(FM))

wilcox.test(genie_result, hclust_result, alternative = "greater")
```

Wynik, który otrzymujemy jest przybliżony. Genie okazuje się najlepszy i to mimo (być może) nie do końca poprawnej metodologii - porównywaliśmy go z najlepszym z pozostałych algorytmów.

Sprawdźmy wynik porównań wszystkich algorytmów. Musimy tutaj uważać na problem wielokrotnego testowania, ale twórcy funkcji `pairwise.wilcox.test` pomyśleli o tym. Co ciekawe radzą sobie z tym metodą Holma, ale mamy też do wyboru inne metody.

```{r, message=FALSE, warning=FALSE}
pairwise.wilcox.test(result$FM, result$algorithm)
```

Testując wielokrotnie nie ma podstaw do odrzucenia hipotezy że nasz algorytm jest tak samo dobry jak hclust_average, ale wydaje mi się, ze nie ma się czym cieszyć. Nie mamy podstaw do powiedzenia, że wyniki hdbscanu są gorsze niż hclust_complete, a gołym okiem widać że gorsze są.

Okazuje się jednak, że nawet robiąc test jednokrotny nie ma podstaw do odrzucenia hipotezy, że nasz algorytm jest tak samo dobry jak hclust_average. 

```{r, warning=FALSE}
spectral_result <- unlist(result %>% filter(algorithm == "spectral") %>% select(FM))
hclust_result <- unlist(result %>% filter(algorithm == "hclust_average") %>% select(FM))

wilcox.test(spectral_result, hclust_result, alternative = "less")
```

Na koniec porównamy nasz algorytm z hdbscanem.
```{r, warning=FALSE}
spectral_result <- unlist(result %>% filter(algorithm == "spectral") %>% select(FM))
hdbscan_result <- unlist(result %>% filter(algorithm == "hdbscan") %>% select(FM))

wilcox.test(spectral_result, hdbscan_result, alternative = "greater")
```

Należy jednak pamiętać, że hdbscan nie wie o prawdziwej liczbie skupień - jesteśmy zatem nie fair w stosunku do niego.

### Jakie zbiory sprawiały najwięcej problemów analizie skupień?
```{r, cache=TRUE}
result %>% select(benchmark, dataset, FM, AR) %>% 
  group_by(benchmark, dataset) %>% 
  summarize(FM_mean=mean(FM), AR_mean=mean(AR)) %>%
  arrange(FM_mean) 
```

Wygląda na to, że studenci WUTu byli dość złośliwi dobierając zbiory danych.

## Analiza działania spectral clustering

### Jak parametr M wpływa na działanie algorytmu?

Zbadamy teraz jak wybór hiperparametru M wpływa na działanie algorytmu. Posłuzymy się w tym celu poniższą funkcją:
```{r, cache=TRUE}
test_spectral_single <- function(benchmark, dataset, M=20, k=NULL, scale=FALSE, plot=TRUE){
  data <- read_data(benchmark, dataset)
  X <- data$X
  if(scale){
    X <- scale(X)
  }
  Y <- data$Y
  if(is.null(k)){
    k = length(unique(unlist(Y)))
  }
  set.seed(42)  # because kmeans in spectral clustering randomly initializes centers
  Y_pred <- spectral_clustering(X, k, M)
  if(plot){
    plot_data(X, Y_pred, paste(paste(benchmark, dataset, sep="/"), ": spectral ", "M=", M, sep=""))
  }
  print(paste("FM:", FM_index(Y, Y_pred), " AR:", adjustedRandIndex(Y, Y_pred), sep=" "))
}

```

Spójrzmy teraz jak zadziała nasz algorytm dla różnych M. Zwróćmy uwagę, że wyeliminowaliśmy losowość wynikającą z losowego przyporzadkowywania początkowych wartości dla centrowych punktów w algorytmie kmeans.

```{r, cache=TRUE}
Ms <- c(2, 10, 20, 50)
benchmark <- "sipu"; dataset <- "flame"
for(m in Ms){
  print(m)
  test_spectral_single(benchmark, dataset, M=m)
}
```
Jak widzimy dla małego `M` algorytm działa trochę gorzej, natomiast dla wyższych zwiększanie `M` nie zmienia tego jak algorytm przyporządkowuje punkty.

Sprawdżmy jeszcze na to samo dla innych danych:
```{r, cache=TRUE}
Ms <- c(2, 10, 20, 50)
benchmark <- "wut"; dataset <- "twosplashes"
for(m in Ms){
  print(m)
  test_spectral_single(benchmark, dataset, M=m)
}
```

Wyniki potwierdzają naszą tezę, że działanie algorytmu nie zmienia się wraz ze zmianą M o ile M nie jest zbyt małe. Dlatego jako domyślny parametr można przyjąć na przykład M=10.

### Jak skalowanie wpływa na wyniki?
```{r, cache=TRUE}
benchmark <- "sipu"; dataset <- "flame"
test_spectral_single(benchmark, dataset, scale=FALSE)
test_spectral_single(benchmark, dataset, scale=TRUE)
```
W tym przypadku skalowanie trochę pogorszyło działanie algorytmu. Natomiast dla innych zbiorów działanie może być różne:

```{r, cache=TRUE}
test_spectral_single("graves", "dense", M=20)
test_spectral_single("graves", "dense", M=20, scale=TRUE)
```

```{r, cache=TRUE}
test_spectral_single("fcps", "tetra", M=20)
test_spectral_single("fcps", "tetra", M=20, scale=TRUE)
```

Wynika stąd, że skalowanie nie ma wielkiego wpływu na jakość naszego algorytmu. Już podczas testów zauważyliśmy, że algorytm nie przywiązuje dużej uwagi do bliskości punktów i był w stanie łączyć punkty odległe do siebie. Zatem i skalowanie niewiele zmienia w jego działaniu. Intuicja jest taka, że w tej metodzie wykorzystujemy tylko indeksy najbliższych punktów, a zatem konkretne wielkości nie mają takiego znaczenia.

## Wnioski
Nasz algorytm `spectral clustering` działa całkiem nieźle nawet w porównaniu do różnych algorytmów R-owych. Charakteryzuje się tym, że w przeciwieństwie do na przykład `kmeans` nie przywiązuje uwagi do skupisk które są blisko siebie i udaje mu się wychwycić "podobieństwa"" między punktami leżącymi daleko od siebie. Zaobserwowaliśmy, że hiperparametr `M` nie ma dużego wpływu na jakość wykonywanej analizy skupień. Ogólnie `spectral_clustering` nie działa najszybciej, dlatego zaimplementowaliśmy go w Rcpp, co trochę poprawiło czas wykonywania analizy skupień.