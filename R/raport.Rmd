---
title: "Spectral clustering - raport"
author: "Przemysław Kaleta"
date: "January 25, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
```

## Zapisanie wyników benchmarkowych

Poniżej kod skryptu, w którym przetestowałem algorytmy na wszystkich zbiorach benchamrkowych i zapisałem wyniki do pliku `results.csv`.

```{r, eval=FALSE}
library(mclust)
library(dendextend)
library(genie)
library(stringi)

source("spectral.R")


read_data <- function(benchmark, dataset){
  matrix_file_name <- paste(dataset, ".data.gz", sep="")
  labels_file_name <- paste(dataset, ".labels0.gz", sep="")
  matrix_path <- file.path("..", "benchmarks", benchmark, matrix_file_name)
  labels_path <- file.path("..", "benchmarks", benchmark, labels_file_name)
  X <- as.matrix(read.table(matrix_path))
  Y <- as.matrix(read.table(labels_path))
  return(list(X=X, Y=Y))
}

plot_data <- function(X, Y, title=""){
  plot(X[, 1], X[, 2], col=unlist(Y), pch=20)
  title(title)
}

result_spectral <- function(benchmark, dataset, M=20, k=NULL, scale=FALSE, plot=FALSE){
  data <- read_data(benchmark, dataset)
  X <- data$X
  if(scale){
    X <- scale(X)
  }
  Y <- data$Y
  if(is.null(k)){
    k <- length(unique(unlist(Y)))
  }
  set.seed(42)  # because kmeans in spectral clustering randomly initializes centers
  Y_pred <- spectral_clustering(X, k, M)
  if(plot){
    plot_data(X, Y_pred, paste(paste(benchmark, dataset, sep="/"), ": spectral ", sep=""))
  }
  algorithm <- "spectral"
  
  return(list(benchmark=benchmark,
              dataset=dataset,
              algorithm=algorithm,
              FM=FM_index(Y, Y_pred), 
              AR=adjustedRandIndex(Y, Y_pred)))
}


result_hclust <- function(benchmark, dataset, method="complete", k=NULL, scale=FALSE, plot=FALSE){
  data <- read_data(benchmark, dataset)
  X <- data$X
  if(scale){
    X <- scale(X)
  }
  Y <- data$Y
  if(is.null(k)){
    k = length(unique(unlist(Y)))
  }
  
  hc <- hclust(dist(X), method)
  Y_pred <- cutree(hc, k=k)
  
  if(plot){
    plot_data(X, Y_pred, paste(paste(benchmark, dataset, sep="/"), ": hclust ", method, sep=""))
  }
  
  algorithm <- paste("hclust", method, sep="_")
  return(list(benchmark=benchmark,
              dataset=dataset,
              algorithm=algorithm,
              FM=FM_index(Y, Y_pred), 
              AR=adjustedRandIndex(Y, Y_pred)))
}

result_dbscan <- function(benchmark, dataset, k=NULL, scale=FALSE){
  data <- read_data(benchmark, dataset)
  X <- data$X
  if(scale){
    X <- scale(X)
  }
  Y <- data$Y
  if(is.null(k)){
    k = length(unique(unlist(Y)))
  }
  
  Y_pred <- hdbscan(dist(X), minPts=k)$cluster
  
  algorithm <- "hdbscan"
  
  return(list(benchmark=benchmark,
              dataset=dataset,
              algorithm=algorithm,
              FM=FM_index(Y, Y_pred), 
              AR=adjustedRandIndex(Y, Y_pred)))
}

result_kmeans <- function(benchmark, dataset, k=NULL, scale=FALSE){
  data <- read_data(benchmark, dataset)
  X <- data$X
  if(scale){
    X <- scale(X)
  }
  Y <- data$Y
  if(is.null(k)){
    k = length(unique(unlist(Y)))
  }
  
  Y_pred <- dbscan(X)$cluster
  
  algorithm <- "kmeans"
  
  return(list(benchmark=benchmark,
              dataset=dataset,
              algorithm=algorithm,
              FM=FM_index(Y, Y_pred), 
              AR=adjustedRandIndex(Y, Y_pred)))
}

result_genie <- function(benchmark, dataset, k=NULL, scale=FALSE){
  data <- read_data(benchmark, dataset)
  X <- data$X
  if(scale){
    X <- scale(X)
  }
  Y <- data$Y
  if(is.null(k)){
    k = length(unique(unlist(Y)))
  }
  
  hc <- hclust2(dist(X))
  Y_pred <- cutree(hc, k=k)
  
  algorithm <- "genie"

  return(list(benchmark=benchmark,
              dataset=dataset,
              algorithm=algorithm,
              FM=FM_index(Y, Y_pred), 
              AR=adjustedRandIndex(Y, Y_pred)))
}

result <- list()
benchmarks <- c("fcps", "graves", "other", "sipu", "wut")
for(benchmark in benchmarks){
  matrix_ending <- "data.gz"
  labels_ending <- "labels0.gz"
  benchmark_path <- file.path("..", "benchmarks", benchmark)
  datasets <- list.files(benchmark_path)
  for(dataset in datasets){
    if(endsWith(dataset, ".txt")){
      dataset <- stri_sub(dataset, 0, -5)
      print(paste("Currently processing", benchmark, dataset))
      data <- read_data(benchmark, dataset)
      X <- data$X
      Y <- data$Y
      
      # testing hclust methods
      hclust_methods <- c("complete", "average", "mcquitty", "median", "centroid")
      for(method in hclust_methods){
        result <- rbind(result, result_hclust(benchmark, dataset, method=method))
      }
      
      # testing other methods
      result <- rbind(result, 
                      result_genie(benchmark, dataset), 
                      result_spectral(benchmark, dataset),
                      result_dbscan(benchmark, dataset),
                      result_kmeans(benchmark, dataset))
    }
  }
  write.csv2(result, "results.csv")  # writing to have at least partial results
}

write.csv(result, "results.csv")
```

## Analiza wyników
```{r}
result <- read.csv("results.csv")
```

### Ktory algorytm jest najlepszy
```{r}
result %>% select(algorithm, FM, AR) %>% 
  group_by(algorithm) %>% summarise(mean_FM = mean(FM), mean_AR = mean(AR)) %>%
  arrange(desc(mean_FM))
```
Cieszymy się patrząc na te wyniki, bo widzimy że spectral clustering nie jest na końcu. Nie odstaje tak bardzo od metod funkcji `hclust`. Jedynie `genie` znacząco wyprzedza je wszystkie, zarówno dla miary FM jak i (zwłaszcza) AR. 
### Czy genie jest rzeczywiście najlepszy?
Nie ufamy za bardzo tym wynikom. Któryś z algorytmów musiał mieć największy wynik FM, ale być może było to całkiem przypadkowe. Dlatego sprawdźmy czy możemy mówić o statystycznej istotności tego wyniku. 

```{r}
genie_result <- unlist(result %>% filter(algorithm == "genie") %>% select(FM))
hclust_result <- unlist(result %>% filter(algorithm == "hclust_average") %>% select(FM))

wilcox.test(genie_result, hclust_result, alternative = "greater")
```

Wynik, który otrzymujemy jest przybliżony. Genie okazuje się najlepszy i to mimo (być może) nie do końca poprawnej metodologii - porównywaliśmy go z najlepszym z pozostałych algorytmów.

Sprawdźmy wynik porównań wszystkich algorytmów. Musimy tutaj uważać na problem wielokrotnego testowania, ale twórcy funkcji `pairwise.wilcox.test` pomyśleli o tym. Co ciekawe radzą sobie z tym metodą Holma, ale mamy też do wyboru inne metody.

```{r, message=FALSE}
pairwise.wilcox.test(result$FM, result$algorithm)
```

Testując wielokrotnie nie ma podstaw do odrzucenia hipotezy że nasz algorytm jest tak samo dobry jak hclust_average, ale wydaje mi się, ze nie ma się czym cieszyć. Nie mamy podstaw do powiedzenia, że wyniki hdbscanu są gorsze niż hclust_complete, a gołym okiem widać że gorsze są (nie mamy też podstaw do )

Okazuje się, że nawet robiąc test jednokrotny nie ma podstaw do odrzucenia hipotezy, że nasz algorytm jest tak samo dobry jak hclust_average. 

```{r}
spectral_result <- unlist(result %>% filter(algorithm == "spectral") %>% select(FM))
hclust_result <- unlist(result %>% filter(algorithm == "hclust_average") %>% select(FM))

wilcox.test(genie_result, hclust_result, alternative = "less")
```

Na koniec porównamy nasz algorytm z hdbscanem.
```{r}
spectral_result <- unlist(result %>% filter(algorithm == "spectral") %>% select(FM))
hdbscan_result <- unlist(result %>% filter(algorithm == "kmeans") %>% select(FM))

wilcox.test(genie_result, hclust_result, alternative = "greater")
```

Należy jednak pamiętać, że hdbscan nie wie o prawdziwej liczbie skupień - jesteśmy zatem nie fair w stosunku do niego.

### Jakie zbiory były najtrudniejsze?
```{r}
result %>% select(benchmark, dataset, FM, AR) %>% 
  group_by(benchmark, dataset) %>% 
  summarize(FM_mean=mean(FM), AR_mean=mean(AR)) %>%
  arrange(FM_mean)
```

Wygląda na to, że studenci WUTu byli dość złośliwi dobierając zbiory danych.

